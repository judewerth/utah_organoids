# docker compose --env-file=../../.env -f docker-compose-spike_sorting_local_worker.yaml -p utah_organoids_spike_sorting build

# docker compose --env-file=../../.env -f docker-compose-spike_sorting_local_worker.yaml -p utah_organoids_spike_sorting up -d

# docker compose --env-file=../../.env -f docker-compose-spike_sorting_local_worker.yaml -p utah_organoids_spike_sorting down --volumes

version: "2.4"
services:
  spike_sorting_local_worker:
    build:
      # only necessary if rebuilding image
      context: ../../
      dockerfile: ./dist/debian/spike_sorting_local_worker.Dockerfile
      args:
        - PY_VER
        - DEPLOY_KEY
        - REPO_OWNER
        - REPO_NAME
        - REPO_BRANCH=${REPO_BRANCH:-main}
        - WORKER_BASE_HASH
    image: registry.vathes.com/sciops/spike_sorting_local_${REPO_NAME}:py${PY_VER}-debian-${WORKFLOW_VERSION}
    runtime: nvidia
    environment:
      - CONTAINER_USER
      - MATLAB_VERSION
      - DJ_HOST
      - DJ_USER
      - DJ_PASS
      - DATABASE_PREFIX
      - AWS_ACCESS_KEY
      - AWS_ACCESS_SECRET
      - AWSACCESSKEYID=${AWS_ACCESS_KEY}
      - AWSSECRETACCESSKEY=${AWS_ACCESS_SECRET}
      - RAW_ROOT_DATA_DIR=${S3_ROOT_MOUNTPOINT}/inbox
      - PROCESSED_ROOT_DATA_DIR=${OUTBOX_MOUNTPOINT}
      - WORKER_MAX_IDLED_CYCLE
      - BUCKET_NAME
      - REPO_NAME
    cap_add:
      - SYS_ADMIN
    devices:
      - /dev/fuse
    security_opt:
      - apparmor:unconfined
    shm_size: "2g"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ${OUTBOX_MOUNTPOINT}:${OUTBOX_MOUNTPOINT}
      - ${S3_ROOT_MOUNTPOINT}:${S3_ROOT_MOUNTPOINT}
      - /var/run/docker.sock:/var/run/docker.sock
    scale: ${WORKER_COUNT:-1}
    command:
      - /bin/bash
      - -c
      - |
        run_workflow spike_sorting_worker
