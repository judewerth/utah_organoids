# docker compose --env-file=../../.env -f docker-compose-test.yaml -p utah_organoids_spike_sorting_worker build 
version: '2.4'
services:
  spike_sorting_local_worker:
    build:
      # only necessary if rebuilding image
      context: ../../
      dockerfile: ./dist/debian/Dockerfile
      args:
        - PY_VER
        - DEPLOY_KEY
        - REPO_OWNER
        - REPO_NAME
        - REPO_BRANCH=${REPO_BRANCH:-main}
        - WORKER_BASE_HASH
        - SORTER_IMAGE
    image: registry.vathes.com/sciops/spike_sorting_local_${REPO_NAME}:${SORTER_IMAGE}
    runtime: nvidia
    environment:
      - CONTAINER_USER
      - MATLAB_VERSION
      - DJ_HOST
      - DJ_USER
      - DJ_PASS
      - DATABASE_PREFIX
      - AWS_ACCESS_KEY
      - AWS_ACCESS_SECRET
      - AWSACCESSKEYID=${AWS_ACCESS_KEY}
      - AWSSECRETACCESSKEY=${AWS_ACCESS_SECRET}
      - RAW_ROOT_DATA_DIR=/home/${CONTAINER_USER}/s3/inbox
      - PROCESSED_ROOT_DATA_DIR=/home/${CONTAINER_USER}/efs/outbox
      - WORKER_MAX_IDLED_CYCLE
      - BUCKET_NAME
      - REPO_NAME
      - SORTER_IMAGE
    cap_add:
      - SYS_ADMIN
    devices:
      - /dev/fuse
    security_opt:
      - apparmor:unconfined
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    volumes:
      - ${OUTBOX_MOUNTPOINT}:/home/${CONTAINER_USER}/efs/outbox
      - ${S3_ROOT_MOUNTPOINT}:/home/${CONTAINER_USER}/s3
    scale: ${WORKER_COUNT:-1}
    command:
      - /bin/bash
      - -c
      - |
        run_workflow spike_sorting_local_worker
